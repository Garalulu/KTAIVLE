# 0313
## 시각지능 딥러닝
### 1교시
#### Review
- 딥러닝에서 무얼 했나?
    - Tensorflow.keras 사용
    - sequential api: 레이어를 순차적으로 연결
    - functional api: 레이어를 사슬처럼 조절해가며 연결(locally connected 가능. concatenate, add, ...)
    - 데이터 펼치기: reshape / flatten
    - 원핫인코딩: to_categorical
    - 다중 분류
        - loss: categorical_crossentropy
        - metrics: accuracy
        - optimizer: adam
    - 이진 분류
        - loss: binary_crossentropy
        - metrics: accuracy
        - optimizer: adam
    - 회귀
        - loss: mse
        - optimizer: adam

    - validation_split
    - EarlyStopping
---
### 2교시
- Dropout
    - 학습 과정에서 일정 비율 노드를 삭제
    - 초기값에 덜 민감하게
    - overfitting 방지
- Batch Normalization
    - 미니 배치가 학습되는 과정에서 배치 간 데이터의 분포가 확 바뀌는 것을 염려하여 만듦
    - 미니 배치도 스케일링을 해보자
    - hidden layer -> normalization -> activation이 필요하다 라고 주장 // 논쟁거리. 실제에서는 hidden layer -> activation -> normalization이 성능 더 좋았다

#### Review
- 하나의 노드는 앞 레이어 노드들의 값으로부터 뭔지 모르는 간단한 특징 따냄(현실의 무언가와 연결되는지는 알 수 없음)
- 첫 번째 히든 레이어 노드는 인풋 레이어의 노드에서 고려해볼 수 있는 간단한 특징을 잡아낼 수 있는 장치의 모임
- 다음 히든 레이어 노드는 간단하지만 앞 레이어보다 더 깊은 특징 추출
- 노드 수가 어느 정도 특징을 따길 바라는지, 레이어의 수는 어느 정도 계층으로 특징을 따길 바라는지 // 엔지니어의 의도가 담김
- 마지막 레이어는 최종 특징. 인풋과 아웃풋 관계에서 노이즈는 가능한 줄어있고, 신호는 가능한 증폭되어 있는 값

#### 컴퓨터가 이미지를 이해하게 하는 것
- 프로그램을 어떻게 만들어야 하나?
    - Rule-based programming (If, else)
    - Machine Learning
---
### 3교시
#### CNN Basics
- ImageNet: Fei Fei Li
- LeNet / AlexNet: Convolutional Neural Network
---
### 4교시
- 이미지 인식 성능이 그렇게 올라가지 않았다.
- 이미지를 1차원으로 평평하게 하는게 옳은 걸까?
- -> Convolution Layer 등장. Activation Map
#### Convolution Layer
- Layer 크기만큼 부분과 합성곱 진행
- Layer를 여러개 만들어 서로 가중치를 다르게 함
- 레이어 크기가 클수록 정보가 더 손실
- https://qph.cf2.quoracdn.net/main-qimg-b662a8fc3be57f76c708c171fcf29960
- stride를 주면 그 간격만큼 건너뛰어 합성곱
- Output size: (Input size - Filter size) / Stride + 1
---
### 5교시
- Output size가 정수가 되지 않더라도 Padding으로 임의의 칸을 만들어 가능하게 해줌
- padding=same: 이미지 사이즈가 줄지 않게 임의의 칸을 채워준다

#### Pooling
- max pooling
    - 가장 영향을 많이 주는 정보만 가져가겠다
- 연산량을 줄이려는 목적이 가장 큼

#### LeNet 구조
#### AlexNet 구조
---
### 6교시
```python
# 불러오기
import tensorflow as tf
from tensorflow import keras

from tensorflow.keras.backend import clear_session
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D
```
#### 코드
- ``Conv2D(filters=16, padding='same',
                  kernel_size=(3, 3),
                  activation='relu',
                  stride=(1,1))``
    - filters: 제작하려는 Feature map의 수
    - padding: 패딩 여부. 기본값 하면 패딩 없음
    - kernel_size: filter size
    - activation: 활성화 함수
    - stride: filter가 얼마나 촘촘히 훑을 것인가
- ``MaxPool2D(pool_size=(2, 2), stride=None)``
- ``model.compile(loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'],
              optimizer='adam')``
    - ``keras.losses.sparse_categorical_crossentropy``: to_categorical 전처리하지 않고도 알아서 체크해줌!

---
