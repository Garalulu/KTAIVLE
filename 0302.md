# 0302
## 딥러닝
### 1교시
#### Review
- 목표: 연결주의 알고리즘에 대해 알아가는 것
    - Tensorflow & keras (Sequential / Functional API)
    - 회귀
        - Input(shape=(3,))
        - Dense(1)
    - 분류
        - Input(shape=(4,))
        - Dense(1, activation='sigmoid')
        - 0~1 사이로 확률 범위에 들어오게 하기 위해
    - 다중 분류
        - Input(shape=(4,))
        - One-hot Encoding
        - Dense(3, activation='softmax')
        - 여러 확률을 하나의 확률 범위에 들어오게 하기 위해
    - Compile
        - Linear: MSE
        - Logistic: binary crossentropy
        - Multi-class: categorical crossentropy
    - Hidden Layer
        - Dense(5, activation='relu')
        - 0보다 작으면 0, 0 이상이면 그대로
        - 연결된 것으로부터 기존의 없는 새로운 특징을 추출
        - high level 노드 하나 지워도 별 차이 없다: 불필요한 특징
        - low level 노드 하나 넣으니 성능 증가: low level에서 필요한 특징이 존재
    - epochs
        - 학습 가능 데이터를 한 번씩 학습시켰을 때
    - Early Stopping
        - 성능이 개선되지 않을 때 몇 번 더 지켜볼 것인지
---
### 2교시
Yoshua Bengio: 테스트 에러가 증가하지 않을 떄까지 특성 증가
- Learning Rate 조절해가라

MNIST 실습
```python
from tensorflow.keras.callbacks import EarlyStopping

keras.backend.clear_session()
model = keras.models.Sequential()
model.add(keras.layers.Input(shape=(train_x.shape[1],)))
model.add(keras.layers.Dense(10, activation='softmax'))
model.compile(loss='categorical_crossentropy', metrics=['accuracy'],
              optimizer='adam')
es = EarlyStopping(monitor='val_loss',
                   min_delta=0,
                   patience=5,
                   verbose=1,
                   restore_best_weights=True)


model.fit(train_x, train_y, validation_split=0.2, callbacks=[es], epochs=50, verbose=1)
model.summary()
```
---
### 3교시
```python
train_x = train_x.reshape(train_x.shape[0], -1)
test_x = test_x.reshape(test_x.shape[0], -1)
```
- (60000, 28, 28)에서 60000을 제외하고 (28, 28)을 합치라는 뜻
- ``Flatten()``
```python
## min_max 이런 방법도 가능
from sklearn.preprocessing import MinMaxScaler
mm_scale = MinMaxScaler()
train_x = mm_scale.fit_transform(train_x)
test_x = mm_scale.transform(test_x)
```
```python
## 정석
max_num = train_x.max()
min_num = train_x.min()

train_x = (train_x-min_num)/(max_num-min_num)
test_x = (test_x-min_num)/(max_num-min_num)
```
---
### 4교시
- Flatten()
- ``model.add(keras.layers.Input(shape=(28,28)))
model.add(keras.layers.Flatten())``
- 모델 제작 과정에서 reshape 가능
- ANN Fashion MNIST 실습
---
### 5교시
- x값 전처리: min_max scaling
- y값 전처리: one-hot encoding
- CIFAR-10 실습
---
### 6교시
```python
# x 전처리
max_num = train_x.max()
min_num = train_x.min()

train_x = (train_x - min_num) / (max_num - min_num)
test_x = (test_x - min_num) / (max_num - min_num)

# y 전처리
from tensorflow.keras.utils import to_categorical
class_n = len(np.unique(train_y))
train_y = to_categorical(train_y, class_n)
test_y = to_categorical(test_y, class_n)

# 모델 생성
keras.backend.clear_session()
model = keras.models.Sequential()
model.add(keras.layers.Input(shape=(32, 32, 3)))
model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(512, activation='relu'))
model.add(keras.layers.Dense(512, activation='relu'))
model.add(keras.layers.Dense(256, activation='relu'))
model.add(keras.layers.Dense(128, activation='relu'))
model.add(keras.layers.Dense(10, activation='softmax'))
model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),
              metrics=['accuracy'],
              optimizer='adam')
model.summary()

# 모델 fit
from tensorflow.keras.callbacks import EarlyStopping
es = EarlyStopping(monitor='val_loss',
                   min_delta=0,
                   patience=5,
                   verbose=1,
                   restore_best_weights=True)
history = model.fit(train_x, train_y, validation_split=0.2, callbacks=[es],
          epochs=50, verbose=1)

# 모델 평가
performance_test = model.evaluate(test_x, test_y)

print('Test Loss : {:.6f},  Test Accuracy : {:.3f}%'.format(performance_test[0], performance_test[1]*100))

pred_train = model.predict(train_x)
pred_test = model.predict(test_x)

single_pred_train = pred_train.argmax(axis=1)
single_pred_test = pred_test.argmax(axis=1)

logi_train_accuracy = accuracy_score(train_y.argmax(axis=1), single_pred_train)
logi_test_accuracy = accuracy_score(test_y.argmax(axis=1), single_pred_test)


print('트레이닝 정확도 : {:.2f}%'.format(logi_train_accuracy*100))
print('테스트 정확도 : {:.2f}%'.format(logi_test_accuracy*100))
```
- 컬러 데이터로 넘어오니 정확도가 40%밖에 되지 않는다.
- 다음 넘어가기 전에 Functional로 back

### Functional style
1. 세션 클리어
2. 레이어 사슬처럼 엮기
3. 모델의 시작과 끝 지정
4. 컴파일
5. 요약

- 모델 이름이 명시됨
- 이전 레이어와 직접 연결
- Input Layer가 요약에 보임
```python
# clear
keras.backend.clear_session()

# chain
input_layer = keras.layers.Input(shape=(1,))
output_layer = keras.layers.Dense(1, activation='sigmoid')(input_layer)

# merge
model = keras.models.Model(inputs=input_layer, outputs=output_layer)

# compile
model.compile(loss='mse', optimizer='adam')

# summary
model.summary()
```
---
