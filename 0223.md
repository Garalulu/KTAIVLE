# 0223
### 3교시
## K-Fold Cross Validation
- 테스트하기 전에는 성능을 예측할 수 없다
- 그럼 어떻게? 트레인 데이터에서 일부를 검증용 데이터로 사용4
####  random split
- 검증용 데이터가 모델의 일반화된 성능을 예측할 수 있게 도와줌
- 단, 하나의 데이터셋에서 얻은 성능으로 정확도에 확신을 가질 수 없다

#### K-분할 검증
- 모든 데이터가 평가에 1번, 학습에 k-1번
- k개의 분할에 대한 모든 성능 추정치
    - 반복학습과 평가로 정확도 향상
    - 데이터 편향 방지
    - 반복횟수가 많아 모델 학습과 평가에 많은 시간 소요
- ``cross_val_score``
- ``cv_score = cross_val_score(model, x_train, y_train, cv=10, scoring='accuracy')`` // accuracy 말고 recall 등도 구할 수 있음
- 기본 분할 개수는 5
---
### 4교시
- 거리가 언급이 되면 정규화가 필요함 // SVM, KNN
    - 나머지는 정규화 해도안해도 똑같음!
- 실제로 하는게 아니라 여러 모델에 대해 미리 성능 예측을 하여 모델 선정에 도움을 주는 것!
---
### 5교시
## 하이퍼파라미터 튜닝
- 파라미터 값을 바꾸면 모델의 성능이 달라짐
- 파라미터마다 검증해서 모델을 새로 만들고 학습을 다시 한 후 성능을 평가하기가 너무 번거롭다
- 튜닝 방법에는 정답이 없음
- 다양한 시도를 해보자!
    - Grid Search
    - Random Search
### KNN
- k값(n_neighbors)
    - 보통 데이터 건수의 제곱근으로 결정하는 경우가 있음
- 거리 계산법(metric)
    - Euclidean Distance: 변위
    - Manhattan Distance: 맨해튼 거리의 빌딩을 피해 이동해

### Decision Tree
- max_depth
    - 트리의 최대 깊이 제한
    - 기본값: 완벽하게 클래스 결정 값이 될때까지 깊이를 계속 키우며 분할하거나, 노드가 가지는 데이터 개수가 min_samples_split보다 작아질때까지 깊이 증가
- min_samples_leaf
    - leaf가 되기 위한 최소 샘플 데이터 수
- min_samples_split
    - 노드를 분할하기 위한 최소한의 데이터 수

## Random Search, Grid Search
- KNN - 최선의 n_neighbors 설정?
- 파라미터의 값을 어떻게 비교해볼 것인가
1. 1~n 구간의 정수를 다 넣어서 비교 - Grid Search
2. 1~n 구간의 정수 중 임의의 m개만 골라 비교 - Random Search
- 딕셔너리 형태로 파라미터 설정
```python
param = {'n_neighbors': range(1, 101),
         'metric': ['euclidean', 'manhatten']}
```