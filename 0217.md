# 0217
## 웹크롤링2
### 1교시
#### review
- Server - Client 관계 기억하기
- 주로 80 / 443 port로 요청
- GET: query로 전송. url에 데이터 포함
- POST: body로 전송. url에 데이터 포함 x
- requests 모듈로 데이터 수집
- selenium : 웹브라우저를 python 코드로 컨트롤해서 데이터 수집
- 정적 페이지(URL 변화) - html(str) > BeautifulSoup > css selector > DataFrame
- 동적 페이지(URL 변화 없이 데이터 수정) - json(str) > response.json() > DataFrame

##### 웹크롤링 절차
1. 웹 서비스 분석(개발자도구), API문서 : URL 찾기
2. request(URL) > response(data) : data(json(str), html(str))
3. data(json(str), html(str)) > response.json(), BeautifulSoup(css-selector) > DataFrame

##### 에러 발생시
- header 수정해서 데이터 요청
    - ``user-agent``, ``referer``
---
