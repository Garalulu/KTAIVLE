# 0309
## AI 모델 해석/평가
### 1교시
#### 목표
- Review ML/DL
- 비즈니스를 위한 인공지능
- 모델 설명에 대한 요구
- 모델에 대한 설명 1. 변수 중요도

---
### 2교시
### 튜닝 모델 그래프 그리기
```python
result = pd.DataFrame(model_kn.cv_results_)
plt.figure(figsize = (10,6))
sns.lineplot(x='param_n_neighbors',
             y='mean_test_score',
             data = result,
             marker = 'o',
             hue = 'param_metric')
plt.grid()
plt.show()
```
---
### 3교시
https://colab.research.google.com/drive/1i5TBatDaXm5iiBdeXAAIQnZV0EM9JPJX
### 튜닝 파라미터
- KNN
    - params = {'n_neighbors': range(3, 100, 2),
          'metric': ['euclidean', 'manhattan']}
- SVC
    - params = {'C':[1, 10, 20, 30], 'gamma':np.linspace(0.001, 0.2, 50)}
- Random Forest
    - n_estimators, max_features: 분기마다 사용할 특성 수
- ``np.linspace(start, last, times)``
    - 시작점부터 끝점까지 n회로 나눈 리스트
- XGB
    - params = {'learning_rate':np.linspace(0.01,0.5, 50), 'n_estimators':[150]}

- 과연 recall, precision 등에서 어떤 걸 기준으로 모델을 선정해야 할까? 다음 시간에
---
### 4교시
### 정수기 렌탈 비정상 계약 예측
- 연락이 잘 안되고 월 납입금 연체되는 고객 사전에 예측
- 영업팀: 가능한 정상으로 예측 요청
    - KPI: 계약 체결건수, 금액
- 서비스팀: 가능한 비정상으로 예측 요청
    - KPI: 계약 유지율

### 유통점 판매량 예측
- 매장 발주 정확도 높이기 위해 상품 일별 수요량 예측
- 발주 권한 있는 지점장의 반발

1. 모델이 왜 그렇게 예측했나요?
2. 모델은 비즈니스 문제를 해결할 수 있을까요?

#### Interpretabiliy vs Explainability
- 인풋에 대해 왜 그런 결론을 예측
    - Whitebox 모델: 본질적으로 해석 가능
- 설명이 있어야 임직원들 만족시킬 수 이싸

### 비즈니스 시나리오: 신용대출 심사
- 경쟁사의 공격적인 대출 상품 판매로 자사 은행 대출 실적 감소
- 자사 신용평가 결과에 의문을 품고 있음. 신용평가 기준을 완화하여 대출승인 범위 확대 요구
---
### 5교시
### Feature Importance
- 성능이 낮은 모델에서의 변수중요도는 의미 X
```python
# 변수 중요도 plot
def plot_feature_importance(importance, names, topn = 'all'):
    feature_importance = np.array(importance)
    feature_names = np.array(names)

    data={'feature_names':feature_names,'feature_importance':feature_importance}
    fi_temp = pd.DataFrame(data)

    fi_temp.sort_values(by=['feature_importance'], ascending=False,inplace=True)
    fi_temp.reset_index(drop=True, inplace = True)

    if topn == 'all' :
        fi_df = fi_temp.copy()
    else :
        fi_df = fi_temp.iloc[:topn]

    plt.figure(figsize=(10,8))
    sns.barplot(x='feature_importance', y='feature_names', data = fi_df)

    plt.xlabel('importance')
    plt.ylabel('feature names')
    plt.grid()

    return fi_df
```

#### Decision Tree
```python
# 튜닝 과정 로그를 df로 저장
result = pd.DataFrame(model_gs.cv_results_)

plt.figure(figsize = (10,6))
sns.lineplot(x='param_max_depth', y='mean_test_score', data = result, marker='o')
plt.grid()
plt.show()
```

#### Random Forest
- 각 estimator마다 변수 중요도
```python
fi = x_train.iloc[0:0]
for i in range(n_est) :
    fi.loc[i] = model.estimators_[i].feature_importances_
```


#### XGB
1. weight
    - 모델 전체에서 해당 feature가 split될 때
    - plot_importances 기본값
2. gain
    - feature별 평균 information gain
    - model.feature_importances_ 기본값
    - total_gain : feature별 information gain의 총합
3. cover
    - feature가 split될 때 샘플 수의 평균
    - total_cover: 샘플 수의 총합

- XGB의 plot_tree로 개별 트리 하나를 시각화할 수는 있지만 설명 시도에는 도움 X
---
### 6교시
#### Resampling
- class balance를 맞추기 위한 SMOTE
- ``from imblearn.over_sampling import SMOTE``
- 전체 오차가 가장 적어지는 모델 만듦 
    1. Down: 개체 수가 적은 쪽으로 맞춤 (데이터 제거)
    2. Up: 개체 수가 많은 쪽으로 맞춤 (복원추출로 뻥튀기)
    3. Smote: 개체 수가 많은 쪽으로 맞춤 (보간법으로 뻥튀기)
- 3가지 방법 다 보통 큰 차이는 없음
- 대부분의 상황은 imbalance하다

```python
smote = SMOTE()
x_train_s, y_train_s = smote.fit_resample(x_train, y_train)
```
---
### 7교시
### 엘보우 지점
- 변수 중요도에서 어디까지가 중요한 변수인지
- 꺾이는 부분 찾기

### Permutation Feature Importance (PFI)
- 알고리즘과 상관없이 변수 중요도 파악하는 방법
- Feature 하나 데이터를 무작위로 섞어 모델 score가 얼마나 감소하는지 계산 (여러번 반복 후 평균을 구해 차이 구함)
- 단점: 다중 공선성이 있는 변수가 존재할 때 특정 변수 하나가 섞이면 관련된 변수는 그대로 있으므로 score가 별로 줄어들지 않을 수 있음
- ``from sklearn.inspection import permutation_importance``
- ``pfi = permutation_importance(x_val, y_val, n_repeats=10, random_state=2022)``
```python
# feature별 score 분포
plt.figure(figsize = (10,8))
for i,vars in enumerate(list(x)) :
    sns.kdeplot(pfi1.importances[i], label = vars)

plt.grid()
plt.legend()
plt.show()

# boxplot
sorted_idx = pfi1.importances_mean.argsort()
plt.figure(figsize = (10, 8))
plt.boxplot(pfi1.importances[sorted_idx].T, vert=False, labels=x.columns[sorted_idx])
plt.axvline(0, color = 'r')
plt.grid()
plt.show()
```