# 0221
## 성능평가
> 평가할 때 test / pred 순서 꼭 지키기!!
### 1교시
### 회귀 모델 성능 평가
- 예측 값과 실제 값에 차이(=오차)가 존재할 것이라 예상
- 오차로 모델 성능 평가

#### 오차 제곱의 합
- Sum Squared Error(SSE): 오차 제곱의 합
- Mean SSE(MSE): SSE의 평균
- Root MSE(RMSE): MSE의 제곱근

#### 오차 절대값의 합
- Mean Absolute Error(MAE): 오차 절대값의 합의 평균
- Mean Absolute Percentage Error(MAPE): 오차 / 원본 절대값의 합의 평균
> SSE, MSE, MAE가 최소가 되는 모델이 제일 좋다

> 모델에게 허용된 최대 오차 범위는 평균
---
### 2교시
#### 오차를 바라보는 다양한 관점
- SSE: 전체 오차 중에서 회귀식이 잡아내지 못한 오차
- SST: 평균의 오차
- SSR: 전체 오차 중에서 회귀식이 잡아낸 오차
- SSR = SST - SSE
#### 결정 계수 R-squared
> $R^2 = \frac{SSR}{SST}$ = $1-SSE\over SST$
- 전체 오차 중에서 회귀식이 잡아낸 오차 비율
- 결정계수가 클수록 모델 성능이 좋다

#### 코드
- MAE
```python
# 모듈 불러오기
from sklearn.metrics import mean_absolute_error

# 성능 평가
print("MAE:", mean_absolute_error(y_test, y_pred))
```
- MSE
```python
# 모듈 불러오기
from sklearn.metrics import mean_squared_error

# 성능 평가
print("MSE:", mean_squared_error(y_test, y_pred))
```
- RMSE
```python
# 모듈 불러오기
from sklearn.metrics import mean_squared_error

# 성능 평가
print("RMSE:", mean_squared_error(y_test, y_pred)**(0.5))
# print("RMSE:", mean_squared_error(y_test, y_pred, squared=False))
```
- MAPE
```python
# 모듈 불러오기
from sklearn.metrics import mean_absolute_percentage_error

# 성능 평가
print("MAPE:", mean_absolute_percentage_error(y_test, y_pred))
```
- R2 score
```python
# 모듈 불러오기
from sklearn.metrics import r2_score

# 성능 평가
print("R2:", r2_score(y_test, y_pred))
# print(model.score(x_test, y_test))
```
- 회귀모델에서 보통 score라고 하면 R2 score 사용
---
### 3교시
### 분류 모델 성능 평가
#### 평가 지표
- Confusion Matrix
- 0: Negative / 1: Positive
- 정확도 Accuracy: 전체 중에 맞은 비율
- 정밀도 Precision: 예측한 것 중에 맞은 비율
- 재현율(민감도) Recall: 실제 positive 중에 맞은 비율
- 정확도만으로 모델의 성능을 평가하기 어렵기 때문에 다양한 평가 지표 존재

#### Precision
- Positive라 예측한 것 중에서 실제로 Positive인 비율
- 낮을 경우?
    - 비가 오지 않는데 비가 온다고 해서 불필요한 수고 발생
    - 암이 아닌데 암이라 했으니 불필요한 치료 발생

#### Specificity 특이도
- Precision와 유사하나 Negative 기준
---