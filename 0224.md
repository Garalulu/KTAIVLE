# 0224

### 1교시
## Grid & Random Search
- 내부적으로 K-Fold Cross Validation을 위해 cv값을 지정하므로 실제 수행되는 횟수는 파라미터 조합 수 * cv값
```python
model = RandomizedSearchCV(model_dt,      # 기본 모델
                           param,         # 파라미터 범위
                           cv=5,          # k-fold CV 폴더 개수
                           n_iter=20,     # 랜덤 시도 횟수
                           scoring='r2')  # 사용할 평가지표
```
---
### 2교시
- `sklearn.model_selection`에서 import
- `model.cv_results_['mean_test_score']`: 테스트로 얻은 성능
- `model.best_params_`: 최적의 파라미터
- `model.best_score_`: 최고의 성능
- `model.best_estimator_`: 최고의 모델
---
### 3교시
## Ensemble
- 여러 모델을 결합하여 훨씬 강력한 모델을 생성하는 기법
### Voting
- 여러 모델이 투표를 통해 결과 산출
- Hard Voting: 투표 결과값 중에서 가장 많은 값 선정
- Soft Voting: 각 확률의 평균을 구해 최종 예측
```python
# 선언하기
estimators = [('lr', LinearRegression()),
              ('dt', DecisionTreeRegressor()),
              ('knn', make_pipeline(MinMaxScaler(), KNeighborsRegressor())),
              ('rdf', RandomForestRegressor()),
              ('lgb', LGBMRegressor())]

model = VotingRegressor(estimators=estimators)
```
### Bagging
- 한 모델로 데이터를 분할하여 각각 학습시킨 후 투표/평균을 통해 결과 산출
- 데이터 분할 시 중복 허용
---
### 4교시
- 랜덤 포레스트 ``from sklearn.ensemble import RandomForestClassifier``
    - 여러 Decision Tree 모델이 전체 데이터에서 Bagging 방식으로 각자의 데이터 샘플링
    - 개별 모델이 트리를 구성할 때 분할 기준이 되는 Feature를 랜덤하게 선정
        - 무작위로 뽑은 n개의 Feature들 중 가장 정보 이득이 큰 Feature를 기준으로 트리 분할 -> 개별 모델마다 다른 구조의 트리 구성
    - 개별적으로 학습 수행 후 모든 결과를 집계하여 최종 결과 결정
    - ``n_estimators``: 트리 몇 개? 기본 100

### Boosting
- 같은 유형의 알고리즘 기반 분류기 여러 개에 대해 순차적으로 수행
- 이전 분류기 예측이 틀린 데이터에 대해 다음 분류기에 가중치를 부여하면서 학습과 예측 진행
- XGBoost, LightGBM
```python
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
```

### Stacking
- 여러 모델의 예측 값을 최종 모델의 학습 데이터로 사용
- 현실 모델에서 많이 사용되지 않음
- 기본 모델로 4개 이상 사용해야 좋은 결과 기대 가능
```python
model = StackingClassifier(estimators=estimators,
                           final_estimator= RandomForestClassifier())
```

