# 0331
## 언어지능 딥러닝
### 1교시
### Review
- tokenizer에서 index 수치는 단순히 분류용이지 특별한 값이 아니다 (txt seq -> idx seq)
    - cat: 10, dog: 50일 때 cat 5개 모여서 dog가 되지 않는다
- embedding으로 index를 여러 개 숫자로 변환 => representation
    - 내 목적에 맞도록 error를 낮춤
- RNN -> LSTM -> GRU
- Bidirectional
- Conv1D, MaxPool1D: 시점 축소! 금붕어들에게 매우 효율적인 기능
- 각 레이어의 특징을 알면 본인의 의도를 모델링에 넣고 테스트해볼 수 있다!
---
### 2교시
- 전처리 규칙의 기준은 항상 트레이닝 셋 기준
---
### 3교시
### Seq to Seq
- 단어를 다른 단어로 - 번역
- Encoder와 Decoder
- Encoder - Context - Decoder
- Decoder의 initial state는?
- Encoder와 Decoder에서 문장 길이가 다른 이슈
    - start of speech, end of speech를 넣어 해결
    - sos: 지시용 token
    - eos: 모델 -> 사람 "나 끝났어" 알림
- Decoder 인풋에 정답이 아닌 값이 들어가면 학습이 이상해질 수 있으므로 예측값을 넣지 않고 정답만 넣음 -> Teacher Forcing
---