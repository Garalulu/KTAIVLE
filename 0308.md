# 0308

## 측정치
robust
RF: 0.9562040821816096
Grid: 0.9609514268068022 // n_estimators: 200, criterion: entropy, bootstrap: True

micro F1 score: 0.9603960396039604
0.939

standard
RF: 0.9572615246169253
Grid: 0.9607897153351699 // n_estimators: 200, criterion: entropy, bootstrap: True

micro F1 score: 0.9609907120743034
0.937

## 전처리
### train
- 결측치 dropna로 제거 (1개라서)
- VIF: 범주형 데이터를 제외하고 다중공선성 체크하여 html_num_tags('applet'), url_len, url_domain_len, url_entropy, html_num_tags('head') 제거
- 범주형 데이터 get_dummies 하니까 성능 떨어짐
- val 데이터를 만들어 제출 전 성능 테스트
## test
- KNN Imputer로 결측치 채움
- RobustScaler로 스케일링(StandardScaler보다 cv score는 낮지만 결과는 더 좋았음// 0.939, 0.937)
- to_categorical로 원핫인코딩

### 모델
- randomforest 기본
- randomforest gridsearch: n_estimators: 200, criterion: entropy, bootstrap: True


### 다른 조
- XBNet // 0.87
- TabNet // 0.93  
    - 결측값 있어도 전처리 없이 값 채움
- LGBM + Hyperband Parameter Search // 0.97
    - 깊고 비대칭적인 트리
- Catboost + Hyperband Parameter Search // 0.98
- XGBoost 
- AutoML
https://github.com/mljar/mljar-supervised