# 0227
## 딥러닝
### 1교시
#### 목표
- 딥러닝을 공부하기 위한 기본 토대를 쌓는다
1. 선형 회귀 & 로지스틱 회귀 & 멀티 클래스 분류
2. Artificial Neural Network 다루기
3. Feature Representation, Connection

#### 선형 회귀 - 뉴럴 네트워크 구조
- 가중치와 특성들
- 가중치: 특성들을 다음 단계와 연결
- 특성: Input 노드!

```python
import tensorflow as tf
from tensorflow import keras
```
#### 1) Sequential API
- ``Input(shape=(3,))``: 특성 3개
- ``Dense()``: 종착지(모든 노드가 연결된), Fully-Connected
---
### 2교시
```python
# 1번 청소 : 이미 만들어진 모델이 있다면 그 모델을 없애줘
keras.backend.clear_session()

# 2번 모델 선언
model = keras.models.Sequential()

# 3번 모델 블록 조립
model.add( keras.layers.Input(shape=(1,)) )
model.add( keras.layers.Dense(1) )

## 오리지널 Sequential API
# model.add( keras.layers.Dense(1, input_shape=(1,)) )

# 4번 컴파일 
model.compile(loss='mse',
              optimizer='adam')
```
``model.fit(x, y, epochs=10, verbose=1)``: 10번 학습, 진행 상황 표시
``model.predict(x)``: 예측

- Input / Dense가 차곡 차곡 연결되어 Sequential API 구현
- 클리어 세션 - 모델 선언 - 모델 블록 조립 - 컴파일 - 학습 - 예측
---
### 3교시
#### 로지스틱 회귀 - 아이스크림 방문 구매
- 목표: 아이스크림을 방문 구매할 확률 계산
- 마지막에 어떻게 해야 할까? sigmoid 함수로 결과값을 0~1 사이로 축소 ``activation='sigmoid'``
- ``model.compile(loss='binary_crossentropy', metrics=['accuracy'],
              optimizer='adam')``
- 분류 문제이므로 loss는 'binary_crossentropy', metrics로 accuracy 사용
```python
# 혹시 이미 그려둔 그래프가 있다면 날려줘!
keras.backend.clear_session()

# model에 순차적으로 레이어를 쌓아가겠다는 의도!
model = keras.models.Sequential()

# model에 인풋 값을 받는 레이어를 넣음
model.add( keras.layers.Input(shape=(1,)) )
# model에 Dense 레이어를 넣을거야 (최초의 레이어) : weight를 곱하고, bias를 더해주는 과정
model.add( keras.layers.Dense(1, activation='sigmoid') )


# 오리지널 Sequential API
# model.add( keras.layers.Dense(1, input_shape=(1,), activation='sigmoid') )

# 컴파일 해주렴
model.compile(loss='binary_crossentropy', metrics=['accuracy'],
              optimizer='adam')
```
---
### 4교시
- hack 폰트 찾아봐야지
- 인풋 데이터를 살펴보고 Input shape를 어떻게 할 지 생각해보자
---
